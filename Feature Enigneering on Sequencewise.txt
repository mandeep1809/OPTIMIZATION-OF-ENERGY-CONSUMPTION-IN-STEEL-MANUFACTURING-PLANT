1) Feature Enigneering on temporal data
(2) Feature Enigneering on Numerical Data
(3) Feature Enigneering on Categorical data

If your work hours are 08:30 AM - 05:30 PM GMT, then in IST (Indian Standard Time, which is GMT +5:30), it would be:

Monday to Friday
IST: 02:00 PM - 11:00 PM
GMT: 08:30 AM - 05:30 PM


import pandas as pd
import matplotlib.pyplot as plt
from feature_engine.outliers import Winsorizer
from sqlalchemy import create_engine, text
from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score
from scipy.cluster.hierarchy import linkage, dendrogram


data = pd.read_csv(r'C:/Users/dell/OneDrive/Documents/PDS_01_360_DIGITMG/project/Dataset/updated_dataset.csv')


data.columns = data.columns.str.strip().str.replace(r'\s+', '_', regex=True)


print(data.columns)


user = "new"
password = "new"
database = "airlines"

engine = create_engine(f"mysql+pymysql://{user}:{password}@localhost/{database}")


data.to_sql("airlines_table", con=engine,if_exists='replace', chunksize=1000, index=False)

sql_data = 'select * from airlines_table'

sql_data

data_sql = pd.read_sql_query(text(sql_data), engine)


# data_sql = pd.read_sql_query(text(sql_data), engine.connect())

data.info()

data.describe()

data_sql.columns

data = data.drop(columns=['SRNO', 'DATETIME'])


data.dtypes


for col in data.columns:

    print("column name :", col)

    if data[col].dtype in ('int64', 'float64'):

        print(data[col].mean())
        print(data[col].median())
        print(data[col].mode()[0])
        print(data[col].var())
        print(data[col].std())

        plt.hist(data[col])
        plt.show()

    elif data[col].dtype == "object":

        print(data[col].mode()[0])

    else:

        print("cannot perform first bmd")


print(data.isnull().sum())


for col in data.columns:

    if data[col].dtype in ('int64', 'float64'):

        data[col] = data[col].fillna(data[col].mean())

    elif data[col].dtype == 'object':

        data[col] = data[col].fillna(data[col].mode()[0])


print(data.isnull().sum())


print(data.duplicated().sum())


for col in data.columns:

    if data[col].dtype in ('int64', 'float64'):

        print("column name :", col)

        plt.boxplot(data[col])

        plt.show()


for col in data.columns:

    if data[col].dtype in ('int64', 'float64'):

        if data[col].var() == 0:

            print("column:", col)


for col in data.columns:

    if data[col].dtypes in ('int64', 'float64'):

        if data[col].var() == 0:

            continue

        elif col.strip() in ['PIGIRON', 'KWH_PER_MIN', 'BUCKET_NO']:

            win = Winsorizer(capping_method="gaussian", fold=3,
                             tail='both', variables=[col])

        elif col.strip() in [

            'BSM', 'SCRAP_QTY_(MT)', 'INJ1_QTY_(Coke_Injection_Qty)',
            'DRI2_QTY_(MT)(Fines)', 'TA_TIME(Turn_Around_Time)',
            'MELT_TIME_(Melting_Time)', 'E2_CUR_(Electrode_2_Current)',
            'TT_TIME_(Total_Cycle_Time_Including_Breakdown)',
            'E1_CUR_(Electrode_1_Current)', 'E3_CUR_(Electrode_3_Current)',
            'SPOUT_(Bottom_Refractory_Temperature)', 'SI', 'NI', 'N',
            'Total_Charge', 'Hot_Heel_(Left_Over_Liquid_metal_in_EAF)', 'STATIC_WT'

        ]:

            win = Winsorizer(capping_method="iqr", fold=1.5,
                             tail='both', variables=[col])

        else:

            win = Winsorizer(capping_method="quantiles",
                             fold=0.05, tail='both', variables=[col])

        data[col] = win.fit_transform(data[[col]])

        print("winsorization applied for column :", col)


 


encoder = LabelEncoder()

encoder_dict = {}

for col in data.columns:

    if data[col].dtype == "object":

        encoder_dict[col] = LabelEncoder()

        data[col] = encoder_dict[col].fit_transform(data[col])












#clustering












data_for_clustering = data[['ENERGY_(Energy_Consumption)','TT_TIME_(Total_Cycle_Time_Including_Breakdown)', 'Production_(MT)']]


data_for_clustering = pd.DataFrame(data_for_clustering, columns=data_for_clustering.columns)


data_for_clustering.columns



# k mean 


from sklearn.cluster import KMeans


cluster_range = range(2, 4) 
best_score = -1
best_k = None
best_model = None


silhouette_scores = []

for k in cluster_range:
    
    kmeans = KMeans(n_clusters=k, n_init=20, max_iter=500, random_state=42)
    cluster_labels = kmeans.fit_predict(data_for_clustering)
    
    
    score = silhouette_score(data_for_clustering, cluster_labels)
    silhouette_scores.append(score)
    
   
    if score > best_score:
        best_score = score
        best_k = k
        best_model = kmeans


plt.plot(cluster_range, silhouette_scores, marker='o')
plt.title("Silhouette Scores for K-Means")
plt.xlabel("Number of Clusters (k)")
plt.ylabel("Silhouette Score")
plt.xticks(cluster_range)
plt.show()


print(f"Best Silhouette Score: {best_score:.2f}")
print(f"Optimal Number of Clusters (k): {best_k}")

cluster_labels_1 = best_model.labels_

cluster_labels_2 = pd.Series(cluster_labels_1) 

clustered_data = pd.concat([cluster_labels_2, data], axis=1)

clustered_data = clustered_data.rename(columns={0: 'cluster'})

clustered_data.cluster.value_counts()


clustered_data.columns


cluster_means = clustered_data.groupby('cluster')[['Production_(MT)', 'ENERGY_(Energy_Consumption)','TT_TIME_(Total_Cycle_Time_Including_Breakdown)']].mean()
print(cluster_means)


clustered_data['cluster'] = clustered_data['cluster'].replace({1: 'Optimal', 0: 'Non-Optimal'})


print(clustered_data[['cluster']].head(50))



le = LabelEncoder()

clustered_data['cluster'] = le.fit_transform(clustered_data[['cluster']])

# model_building


from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix


X = clustered_data.drop(columns = ['cluster'])
y = clustered_data['cluster']


scaler = StandardScaler()

clustered_data = scaler.fit_transform(clustered_data)

clustered_data = pd.DataFrame(clustered_data)


 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

models = {
 
    "Logistic Regression": LogisticRegression(),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "Random Forest": RandomForestClassifier()   
}


for name, model in models.items():
    
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    print(f"\n{name} Accuracy: {accuracy_score(y_test, y_pred):.2f}")
    print(classification_report(y_test, y_pred))
    cm = confusion_matrix(y_test, y_pred)
    print("Confusion Matrix:")
    print(cm)




        









        


